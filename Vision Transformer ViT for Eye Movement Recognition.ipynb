{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, models, datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure GPU usage\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Dataset Path\n",
    "data_dir = \"./dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 32\n",
    "learning_rate = 1e-4\n",
    "num_epochs = 10\n",
    "img_size = (100, 200)\n",
    "\n",
    "# Data Transformations\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(img_size, scale=(0.8, 1.0)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(img_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "dataset = datasets.ImageFolder(data_dir, transform=data_transforms['train'])\n",
    "num_classes = len(dataset.classes) \n",
    "\n",
    "# 2-Fold Cross Validation\n",
    "folds = 2\n",
    "fold_size = len(dataset) // folds\n",
    "\n",
    "metrics = []\n",
    "\n",
    "for fold in range(folds):\n",
    "    # Split the dataset\n",
    "    val_start = fold * fold_size\n",
    "    val_end = val_start + fold_size\n",
    "    train_indices = list(range(0, val_start)) + list(range(val_end, len(dataset)))\n",
    "    val_indices = list(range(val_start, val_end))\n",
    "\n",
    "    train_set = torch.utils.data.Subset(dataset, train_indices)\n",
    "    val_set = torch.utils.data.Subset(dataset, val_indices)\n",
    "\n",
    "    train_set.dataset.transform = data_transforms['train']\n",
    "    val_set.dataset.transform = data_transforms['val']\n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    # Load Vision Transformer\n",
    "    model = models.vit_b_16(pretrained=True)\n",
    "    model.heads = nn.Sequential(\n",
    "        nn.Linear(model.heads[0].in_features, num_classes)\n",
    "    )\n",
    "    model.to(device)\n",
    "\n",
    "    # Loss and Optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Training and Validation Loop\n",
    "    best_val_acc = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training Phase\n",
    "        model.train()\n",
    "        train_loss, train_correct = 0.0, 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * images.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            train_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "        train_loss /= len(train_set)\n",
    "        train_acc = train_correct.double() / len(train_set)\n",
    "\n",
    "        # Validation Phase\n",
    "        model.eval()\n",
    "        val_loss, val_correct = 0.0, 0\n",
    "        all_preds, all_labels = [], []\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        val_loss /= len(val_set)\n",
    "        val_acc = val_correct.double() / len(val_set)\n",
    "\n",
    "        # Store metrics\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model = model.state_dict()\n",
    "            best_fold = fold\n",
    "\n",
    "        print(f\"Fold {fold+1}, Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # Calculate Confusion Matrix\n",
    "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "    metrics.append({\n",
    "        \"fold\": fold + 1,\n",
    "        \"train_acc\": train_acc.item(),\n",
    "        \"val_acc\": val_acc.item(),\n",
    "        \"train_loss\": train_loss,\n",
    "        \"val_loss\": val_loss,\n",
    "        \"conf_matrix\": conf_matrix\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_model, \"best_vit_model.pth\")\n",
    "print(\"Best model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Metrics\n",
    "for metric in metrics:\n",
    "    print(f\"Fold {metric['fold']}: Train Acc: {metric['train_acc']:.4f}, Val Acc: {metric['val_acc']:.4f}, Train Loss: {metric['train_loss']:.4f}, Val Loss: {metric['val_loss']:.4f}\")\n",
    "    print(f\"Confusion Matrix:\\n{metric['conf_matrix']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the Best Fold\n",
    "best_fold_metrics = max(metrics, key=lambda x: x['val_acc'])\n",
    "print(f\"Best Fold: {best_fold_metrics['fold']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tkintertorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
